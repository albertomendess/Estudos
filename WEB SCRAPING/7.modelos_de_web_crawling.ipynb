{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidando com diferentes layouts de sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    def __init__(self, url, title, body):\n",
    "        self.url    = url\n",
    "        self.title  = title\n",
    "        self.body   = body\n",
    "\n",
    "    def print(self):\n",
    "        print(f\"TITLE: {self.title}\")\n",
    "        print(f\"URL: {self.url}\")\n",
    "        print(f\"BODY: {self.body}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeCNN(url):\n",
    "    bs = BeautifulSoup(urlopen(url))\n",
    "    title = bs.find('h1').text\n",
    "    body = bs.find('div', {'class' : 'article__content'}).text\n",
    "    print('body: ')\n",
    "    print(body)\n",
    "    return Content(url, title, body)\n",
    "    \n",
    "def scrapeBrookings(url):\n",
    "    req = Request(url, headers= {'User-Agent' : 'Brave'})\n",
    "    response = urlopen(req)\n",
    "    bs = BeautifulSoup(response, 'html.parser')\n",
    "    title = bs.find('h1').text\n",
    "    body = bs.find('div', {'class' : 'byo-block'}).text\n",
    "    return Content(url, title, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: \n",
      "            Robotic rulemaking\n",
      "          \n",
      "URL: https://www.brookings.edu/research/robotic-rulemaking/\n",
      "BODY: \n",
      "As it has rocketed to some 100 million active users in record time, ChatGPT is provoking conversations about the role of artificial intelligence (AI) in drafting written materials such as student exams, news articles, legal pleadings, poems, and more. The chatbot, developed by OpenAI, relies on a large language model (LLM) to respond to user-submitted requests, or “prompts” as they are known. It is an example of generative AI, a technology that upends our understanding of who creates written materials and how they do it, challenging what it means to create, analyze, and express ideas.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.brookings.edu/research/robotic-rulemaking/'\n",
    "content = scrapeBrookings(url)\n",
    "content.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body: \n",
      "\n",
      "\n",
      "\n",
      "New York\n",
      "CNN\n",
      "         — \n",
      "    \n",
      "\n",
      "\n",
      "            Twitter’s traditional bird icon was booted and replaced with an image of a Shiba Inu, an apparent nod to dogecoin, the joke cryptocurrency that CEO Elon Musk is being sued over. \n",
      "    \n",
      "\n",
      "            Musk addressed the change Monday afternoon, tweeting, “as promised” above an image of a year-old conversation in which another user suggested that Musk “just buy Twitter” and “change the bird logo to a doge.” \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CNN/Adobe Stock\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Elon Musk's Twitter promised a purge of blue check marks. Instead he singled out one account\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            The doge logo appeared on the site two days after Musk asked a judge to throw out a $258 billion racketeering lawsuit accusing him of running a pyramid scheme to support the dogecoin, according to Reuters.\n",
      "\n",
      "\n",
      "            Lawyers for Musk and Tesla called the lawsuit by dogecoin investors a “fanciful work of fiction” over Musk’s “innocuous and often silly tweets.”\n",
      "    \n",
      "\n",
      "            It wasn’t clear whether the logo change was permanent. Musk has been known to use Twitter to troll both his fans and his critics. \n",
      "    \n",
      "\n",
      "            The price of dogecoin, which is typically volatile, was up more than 20% over the past 24 hours, to about 9 cents. It was trading just under 8 cents Monday morning.\n",
      "    \n",
      "\n",
      "Dogecoin was created December 6, 2013, by a pair of software engineers — as a joke. The name is a nod to the “doge” meme that became popular a decade ago. Its Shiba Inu mascot mimicks that meme: a dog surrounded by a bunch of Comic Sans text in broken English.\n",
      "    \n",
      "\n",
      "TITLE: \n",
      "      Dogecoin jumps after Elon Musk replaces Twitter bird with Shiba Inu\n",
      "    \n",
      "URL: https://www.cnn.com/2023/04/03/investing/dogecoin-elon-musk-twitter/index.html\n",
      "BODY: \n",
      "\n",
      "\n",
      "New York\n",
      "CNN\n",
      "         — \n",
      "    \n",
      "\n",
      "\n",
      "            Twitter’s traditional bird icon was booted and replaced with an image of a Shiba Inu, an apparent nod to dogecoin, the joke cryptocurrency that CEO Elon Musk is being sued over. \n",
      "    \n",
      "\n",
      "            Musk addressed the change Monday afternoon, tweeting, “as promised” above an image of a year-old conversation in which another user suggested that Musk “just buy Twitter” and “change the bird logo to a doge.” \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CNN/Adobe Stock\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Elon Musk's Twitter promised a purge of blue check marks. Instead he singled out one account\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            The doge logo appeared on the site two days after Musk asked a judge to throw out a $258 billion racketeering lawsuit accusing him of running a pyramid scheme to support the dogecoin, according to Reuters.\n",
      "\n",
      "\n",
      "            Lawyers for Musk and Tesla called the lawsuit by dogecoin investors a “fanciful work of fiction” over Musk’s “innocuous and often silly tweets.”\n",
      "    \n",
      "\n",
      "            It wasn’t clear whether the logo change was permanent. Musk has been known to use Twitter to troll both his fans and his critics. \n",
      "    \n",
      "\n",
      "            The price of dogecoin, which is typically volatile, was up more than 20% over the past 24 hours, to about 9 cents. It was trading just under 8 cents Monday morning.\n",
      "    \n",
      "\n",
      "Dogecoin was created December 6, 2013, by a pair of software engineers — as a joke. The name is a nod to the “doge” meme that became popular a decade ago. Its Shiba Inu mascot mimicks that meme: a dog surrounded by a bunch of Comic Sans text in broken English.\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.cnn.com/2023/04/03/investing/dogecoin-elon-musk-twitter/index.html'\n",
    "content = scrapeCNN(url)\n",
    "content.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    \"\"\"\n",
    "    Classe-base comum para todos os artigos/paginas\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url, title, body):\n",
    "        self.url    = url\n",
    "        self.title  = title\n",
    "        self.body   = body\n",
    "\n",
    "    def print(self):\n",
    "        \"\"\"\n",
    "        Função flexível de exibição que controla a saída\n",
    "        \"\"\"\n",
    "        print(f\"URL: {self.url}\")\n",
    "        print(f\"TITLE: {self.title}\")\n",
    "        print(f\"BODY: {self.body}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    \"\"\"\n",
    "    Contém informções sobre a estrutura do site\n",
    "    \"\"\"\n",
    "    def __init__(self, name, url, titleTag, bodyTag):\n",
    "        self.name       = name\n",
    "        self.url        = url\n",
    "        self.titleTag   = titleTag\n",
    "        self.bodyTag    = bodyTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    def getPage(url):\n",
    "        try:\n",
    "            html = urlopen(url)\n",
    "        except Exception:\n",
    "            return None\n",
    "        return BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    def safeGet(bs, selector):\n",
    "        \"\"\"\n",
    "        Função utilitária utilizada para obter uma string de conteúdo de um\n",
    "        objeto Beautiful Soup e um seletor. Retorna uma string vazia caso nenhum\n",
    "        obejto seja encontrado para o seletor especificado.\n",
    "        \"\"\"\n",
    "        selectedElems = bs.select(selector)\n",
    "        if selectedElems is not None and len(selectedElems) > 0:\n",
    "            return '\\n'.join([elem.get_text() for elem in selectedElems])\n",
    "        return ''\n",
    "    \n",
    "    def getContent(website, path):\n",
    "        \"\"\"\n",
    "        Extrai conteúdo de um URL de página específico\n",
    "        \"\"\"\n",
    "        url = website.url+path\n",
    "        bs = Crawler.getPage(url)\n",
    "        if bs is not None:\n",
    "            title   = Crawler.safeGet(bs, website.titleTag)\n",
    "            body    = Crawler.safeGet(bs, website.bodyTag)\n",
    "            return Content(url, title, body)\n",
    "        return Content(url, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteData = [\n",
    "    ['O\\'Reilly',   'https://www.oreilly.com',      'h1',   'div.title-description'],\n",
    "    ['Reuters',     'https://www.reuters.com',      'h1',   'div.ArticleBodyWrapper'],\n",
    "    ['Brookings',   'https://www.brookings.edu',    'h1',   'div.byo-block'],\n",
    "    ['CNN',         'https://www.cnn.com',          'h1',   'div.article__content']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = []\n",
    "for name, url, title, body in siteData:\n",
    "    websites.append(Website(name, url, title, body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.oreilly.com/library/view/web-scraping-with/9781491910283\n",
      "TITLE: Web Scraping with Python\n",
      "BODY: \n",
      "\n",
      "\n",
      "      \n",
      "        Book\n",
      "      description\n",
      "Learn web scraping and crawling techniques to access unlimited data from any web source in any format. With this practical guide, you’ll learn how to use Python scripts and web APIs to gather and process data from thousands—or even millions—of web pages at once.Ideal for programmers, security professionals, and web administrators familiar with Python, this book not only teaches basic web scraping mechanics, but also delves into more advanced topics, such as analyzing raw data or using scrapers for frontend website testing. Code samples are available to help you understand the concepts in practice.\n",
      "Show and hide more\n",
      "\n",
      "Publisher resources\n",
      "View/Submit Errata\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Crawler.getContent(\n",
    "    websites[0],\n",
    "    '/library/view/web-scraping-with/9781491910283'\n",
    ").print()\n",
    "\n",
    "# Crawler.getContent(\n",
    "#     websites[1],\n",
    "#     '/article/us-usa-epa-pruitt-idUSKBN19W2D0'\n",
    "# ).print()\n",
    "\n",
    "# Crawler.getContent(\n",
    "#     websites[2],\n",
    "#     'blog/techtank/2016/03/01/idea-to-retire-old-methods-of-policy-education/'\n",
    "# ).print()\n",
    "\n",
    "# Crawler.getContent(\n",
    "#     websites[3],\n",
    "#     '/2023/04/03/investing/dogecoin-elon-musk-twitter/index-html'\n",
    "# ).print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estruturando crawlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastreando sites por meio de pesquisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    \"\"\"\n",
    "    Classe-base comum para todos os artigos/páginas\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, topic, url, title, body):\n",
    "        self.topic  = topic\n",
    "        self.url    = url\n",
    "        self.title  = title\n",
    "        self.title  = body\n",
    "\n",
    "    def print(self):\n",
    "        \"\"\"\n",
    "        Função flexível de exibição que controla a saída\n",
    "        \"\"\"\n",
    "        print(f\"New article found for topic: {self.topic}\")\n",
    "        print(f\"URL: {self.url}\")\n",
    "        print(f\"TITLE: {self.title}\")\n",
    "        print(f\"BODY:\\n{self.body}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    \"\"\"Contém informações sobre a estrutura do site\"\"\"\n",
    "\n",
    "    def __init__(self, name, url, searchUrl, resultListing, resultUrl, \n",
    "                 absoluteUrl, titleTag, bodyTag):\n",
    "        self.name           = name\n",
    "        self.url            = url\n",
    "        self.searchUrl      = searchUrl\n",
    "        self.resultListing  = resultListing\n",
    "        self.resultUrl      = resultUrl\n",
    "        self.absoluteUrl    = absoluteUrl\n",
    "        self.titleTag       = titleTag\n",
    "        self.bodyTag        = bodyTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    def __init__(self, website):\n",
    "        self.site   = website\n",
    "        self.found  = {}\n",
    "\n",
    "    def getPage(url):\n",
    "        try:\n",
    "            html = urlopen(url)\n",
    "        except Exception:\n",
    "            return None\n",
    "        return BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    def safeGet(bs, selector):\n",
    "        \"\"\"\n",
    "        Função utilitária utilizada para obter uma string de conteúdo de um\n",
    "        objeto Beautiful Soup e um seletor. Retorna uma string vazia caso nenhum\n",
    "        obejto seja encontrado para o seletor especificado.\n",
    "        \"\"\"\n",
    "        selectedElems = bs.select(selector)\n",
    "        if selectedElems is not None and len(selectedElems) > 0:\n",
    "            return '\\n'.join([elem.get_text() for elem in selectedElems])\n",
    "        return ''\n",
    "\n",
    "    def getContent(self, topic, url):\n",
    "        \"\"\"\n",
    "        Extrai conteúdo de um URL de página específico\n",
    "        \"\"\"\n",
    "\n",
    "        bs = Crawler.getPage(url)\n",
    "        if bs is not None:\n",
    "            title   = Crawler.safeGet(bs, self.site.titleTag)\n",
    "            body    = Crawler.safeGet(bs, self.site.bodyTag)\n",
    "            return Content(topic, url, title, body)\n",
    "        return Content(topic, url, '', '')\n",
    "    \n",
    "    def search(self, topic):\n",
    "        \"\"\"\n",
    "        Realiza uma busca em um site específico por um determinado tópico\n",
    "        e registra todas as páginas encontradas.\n",
    "        \"\"\"\n",
    "\n",
    "        bs = Crawler.getPage(self.site.searchUrl + topic)\n",
    "        searchResults = bs.select(self.site.resultListing)\n",
    "        for result in searchResults:\n",
    "            url = result.select(self.site.resultUrl)[0].attrs['href']\n",
    "            # Verifica se é um URL relativo ou absoluto\n",
    "            url = url if self.site.absoluteUrl else self.site.url + url\n",
    "            if url not in self.found:\n",
    "                self.found[url] = self.getContent(topic, url)\n",
    "            self.found[url].print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteData = [\n",
    "    [\"Reuters\",\n",
    "     \"http://reuters.com\",\n",
    "     \"https://www.reuters.com/search/news?blob=\",\n",
    "     \"div.search-result-indiv\",\n",
    "     \"h3.search-result-tile a\", \n",
    "     False, \n",
    "     'h1', \n",
    "     \"div.ArticleBodyWrapper\"],\n",
    "\n",
    "    [\"Brookings\",\n",
    "     \"http://www.brookings.edu\",\n",
    "     \"https://www.brookings.edu/search/?s=\",\n",
    "     \"div.article-info\", \"h4.title a\",\n",
    "     True,\n",
    "     \"h1\",\n",
    "     \"div.core-block\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = []\n",
    "for name, url, search, rListing, rUrl, absUrl, tt, bt in siteData:\n",
    "    sites.append(Website(name, url, search, rListing, rUrl, absUrl, tt, bt))\n",
    "\n",
    "crawlers    = [Crawler(site) for site in sites]\n",
    "topics      = ['python', \"data%20science\"]\n",
    "\n",
    "for topic in topics:\n",
    "    for crawler in crawlers:\n",
    "        crawler.search(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
